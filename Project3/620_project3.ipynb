{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA620 Project 3 - Name Gender Classifier\n",
    "Team: Mia Chen / Wei Zhou\n",
    "\n",
    "Date: 7/2/2020\n",
    "\n",
    "Recording [link](https://www.youtube.com/watch?v=QOZDLexcjqk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "Using any of the three classifiers described in chapter 6 of <b><i>Natural Language Processing with Python</b></i>, and any features you can think of, build the best name gender classifier you can.\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "Source: <i>Natural Language Processing with Python</i>, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list of examples and corresponding class labels\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "\n",
    "# Combine male and female names\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "        [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "# Shuffle the list\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Herold', 'male'),\n",
       " ('Paula-Grace', 'female'),\n",
       " ('Howard', 'male'),\n",
       " ('Mae', 'female'),\n",
       " ('Noelle', 'female'),\n",
       " ('Meagan', 'female'),\n",
       " ('Gussy', 'female'),\n",
       " ('Paloma', 'female'),\n",
       " ('Agna', 'female'),\n",
       " ('Blinni', 'female')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View 10 random names and corresponding gender\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7,944 names in the corpus. We'll begin by splitting them into three subsets:\n",
    "\n",
    "* test set: 500 words\n",
    "* dev-test set: 500 words\n",
    "* training set: remaining 6,900 words\n",
    "\n",
    "We will start with the example name gender classifier, then make incremental improvements and check with the dev-test set, and finally check with the test set to compare performance on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = names[:500]\n",
    "devtest_names = names[500:1000]\n",
    "train_names = names[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Example 1\n",
    "\n",
    "First step is to define a feature extractor function which build a dictionary containing relevant information about a given name. In this example, we choose the last letter of a given name to be the feaure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the feature extractor to process the names data, and divide the resulting list of feature sets into a training set and a test set. The training set is used to train a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "\n",
    "# Extract the features using the function we defined\n",
    "# feature_sets = [(gender_features(n), gender) for (n, gender) in names]\n",
    "\n",
    "# Split into train and test sets\n",
    "# train_set, test_set = feature_sets[500:], feature_sets[:500]\n",
    "\n",
    "# Apply_features function\n",
    "from nltk.classify import apply_features\n",
    "\n",
    "# Split into train and test sets\n",
    "train_set = apply_features(gender_features, names[500:])\n",
    "test_set = apply_features(gender_features, names[:500])\n",
    "\n",
    "# Train a Naive Bayes Classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Accuracy of Example 1\n",
    "from nltk.classify import accuracy\n",
    "print(accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can examine the classifier to determine which features are most effective for distinguishing the name genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     34.2 : 1.0\n",
      "             last_letter = 'k'              male : female =     30.5 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.0 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.9 : 1.0\n",
      "             last_letter = 'v'              male : female =     11.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This listing shows that names that end in 'a' are 34.2 times more likely to be female's; and names that end in 'k' are 30.5 times more likely to be male's.\n",
    "\n",
    "### Book Example 2\n",
    "\n",
    "Try modifiying the gender_features() function to provide the classifier with first letter as an additional feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778\n"
     ]
    }
   ],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features['count(%s)' % letter] = name.lower().count(letter)\n",
    "        features['has(%s)' % letter] = (letter in name.lower())\n",
    "    return features\n",
    "\n",
    "# Split the datasets into test, dev-test and train sets\n",
    "train_set = apply_features(gender_features2, train_names)\n",
    "test_set = apply_features(gender_features2, test_names)\n",
    "devtest_set = apply_features(gender_features2, devtest_names)\n",
    "\n",
    "# Train Naive Bayes Classifier2\n",
    "classifier2 = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Accuracy of example 2\n",
    "print(accuracy(classifier2, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuray is improved by almost 3 percentage points (from 75% to 77.8%).\n",
    "\n",
    "## Book Example 3\n",
    "Continue modifying the feature function using the suffix as a feature. Again, we see an improved performance (from 77.8% to 79.4% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794\n"
     ]
    }
   ],
   "source": [
    "def gender_features3(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:]}\n",
    "\n",
    "# Split the datasets into test, dev-test and train sets\n",
    "\n",
    "train_set = apply_features(gender_features3, train_names)\n",
    "test_set = apply_features(gender_features3, test_names)\n",
    "devtest_set = apply_features(gender_features3, devtest_names)\n",
    "\n",
    "# Train Naive Bayes Classifier3\n",
    "classifier3 = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Accuracy of example 3\n",
    "print(accuracy(classifier3, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the features\n",
    "\n",
    "Combining the above, we include all the features: first letter, last letter, prefix (first 2 letters for a shorter name and first 3 letters for a name with 5 or more letters) and suffix (last 2 letters for a shorter name and last 3 letters for a longer name). The accuracy has improved from 79.4% to 82.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824\n"
     ]
    }
   ],
   "source": [
    "def gender_features4(name):\n",
    "    features = {}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    features['prefix'] = name[:2].lower() if len(name) <= 4 else name[:3].lower()\n",
    "    features['suffix'] = name[-2:].lower() if len(name) <=4 else name[-3:].lower()\n",
    "    return features\n",
    "\n",
    "# Split the datasets into test, dev-test and train sets\n",
    "train_set = apply_features(gender_features4, train_names)\n",
    "test_set = apply_features(gender_features4, test_names)\n",
    "devtest_set = apply_features(gender_features4, devtest_names)\n",
    "\n",
    "# Train Naive Bayes Classifier4\n",
    "classifier4 = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Accuracy of example 4\n",
    "print(accuracy(classifier4, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Performance\n",
    "When we check the final performance of our classifier on the test set, we got a 77.4% accuracy which is less than the 82.4% we saw from testing on the dev-test set. This is somewhat expected since the dev-test set was used to improve feature selection, the model might be biased. Instead of using a separate dev-test set, we can consider using a k-fold cross-validation to tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(classifier4, test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
